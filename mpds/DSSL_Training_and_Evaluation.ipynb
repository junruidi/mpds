{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you use this code, please cite:\n",
    "* Dyagilev, K. and Saria, S., 2016. Learning (predictive) risk scores in the\n",
    "presence of censoring due to interventions. Machine Learning, 102(3),\n",
    "pp.323-348.<br>\n",
    "* Dyagilev, K. and Saria, S., 2015. Learning a severity score for sepsis: A novel approach based on clinical comparisons. In AMIA Annual Symposium Proceedings (Vol. 2015, p. 1890). American Medical Informatics Association."
    ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load your dataset\n",
    "dataset format:\n",
    "id: the patient id and each row needs to include this column\n",
    "the dataset is ordered pair by pair and each pair contains two rows: the first row is the feature vector before medication and second row is the feature vector after medication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "dataset_path = \"\"\n",
    "dataset_name = \"dataset.csv\"\n",
    "dataset = pd.read_csv(os.path.join(dataset_path, dataset_name))\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ids_all = dataset.id.value_counts()\n",
    "ids = ids_all.index.values\n",
    "print len(ids)\n",
    "print dataset.shape\n",
    "dataset = dataset[dataset.id.isin(ids)]\n",
    "print dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split your dataset by rank order (i.e. datasets for before medication and after medication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_before = dataset.iloc[::2]\n",
    "dataset_after = dataset.iloc[1::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment with DSSL's Regularization Parameters (lambda_0, lambda_S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#LO = [1e5] # play with range for lam0 and sweep to choose right regularization penalty\n",
    "LO = [1e7, 1e6, 1e5, 1e4, 1e3, 1e2, 1e1, 1, 1e-1, 1e-2] \n",
    "#LS = [1e-2] # play with range for lambda-S conditioned on choice for lam0\n",
    "LS = [1e7, 1e6, 1e5, 1e4, 1e3, 1e2, 1e1, 1, 1e-1, 1e-2]\n",
    "\n",
    "lo = []\n",
    "ls = []\n",
    "for i in LO:\n",
    "    for j in LS:\n",
    "        lo.append(i)\n",
    "        ls.append(j)\n",
    "print lo\n",
    "print ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reload_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Learning Code for DSSL in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R \n",
    "setwd(\"/dssl\")\n",
    "source(\"dssFunctionLibrary.R\")\n",
    "source(\"dssDataSetSpecificHacks.R\")\n",
    "source(\"dssPerformanceEvaluation.R\")\n",
    "source(\"mimicUsefulFunction.R\")\n",
    "require(gridExtra)\n",
    "require(ROCR)\n",
    "require(ISLR)\n",
    "require(caret)\n",
    "require(magrittr)\n",
    "library(foreach)\n",
    "library(doMC)\n",
    "registerDoMC(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Learn DSSL Model Parameters\n",
    "#### Use Learning Procedure Specified in dssTrain.Linear in dssFunctionLibrary.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model_in_R():\n",
    "    %R -i XTrainScaled,XTrainTimeVector,lo,ls,sm_on_idx,sm_off_idx \n",
    "    %R OrderPairs <- data.frame(onIdx = seq(1, nrow(XTrainScaled)/2, by = 1), offIdx = seq(nrow(XTrainScaled)/2+1, nrow(XTrainScaled), by = 1))\n",
    "    %R SmoothnessPairs <- data.frame(onIdx = sm_on_idx, offIdx = sm_off_idx)\n",
    "    %R -o res res <- dssTrain.Linear(XTrainScaled, OrderPairs, SmoothnessPairs, XTrainTimeVector, lo, ls,\"dssl_mdl_v1_tap2\",doParallel = 1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DSSL Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_accuracy(scores):\n",
    "    length = len(scores)/2\n",
    "    diff = scores[:length] - scores[length:]\n",
    "    accuracy = np.sum(diff >= 0) * 1.0 / len(diff)\n",
    "    return accuracy\n",
    "\n",
    "def evaluate(pairs, weights):\n",
    "    \n",
    "    # Segment design matrix to extract features associated\n",
    "    # with each modality (i.e. smartphone activity)\n",
    "    #\n",
    "    # 0:17 voice\n",
    "    # 17:143 balance \n",
    "    # 143:269 gait \n",
    "    # 269:420 tap \n",
    "    # 420:435 react\n",
    "    scores = pairs.dot(weights)\n",
    "    # 0:17 voice\n",
    "    scores_voice = pairs[:, 0:17].dot(weights[0:17])\n",
    "    # 17:143 balance\n",
    "    scores_balance = pairs[:,17:143].dot(weights[17:143])\n",
    "    \n",
    "    # 143:269 gait\n",
    "    scores_gait = pairs[:,143:269].dot(weights[143:269])\n",
    "    \n",
    "    # 269:420 tap\n",
    "    scores_tap = pairs[:,269:420].dot(weights[269:420])\n",
    "    \n",
    "    # 420: react\n",
    "    scores_react = pairs[:,420:].dot(weights[420: ])\n",
    "    \n",
    "    return {'scores':scores, 'accuracy':get_accuracy(scores), \n",
    "            'scores_voice': scores_voice, 'accuracy_voice':get_accuracy(scores_voice),\n",
    "            'scores_balance': scores_balance, 'accuracy_balance':get_accuracy(scores_balance),\n",
    "            'scores_gait': scores_gait, 'accuracy_gait':get_accuracy(scores_gait),\n",
    "            'scores_tap': scores_tap, 'accuracy_tap':get_accuracy(scores_tap),\n",
    "            'scores_react': scores_react, 'accuracy_react':get_accuracy(scores_react)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Evaluation via K-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# combine select weights and lambda together \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "fold_accuracy = []\n",
    "fold_weights = []\n",
    "fold_train_pt = []\n",
    "fold_test_pt = []\n",
    "fold_scaler = []\n",
    "fold_res_train = []\n",
    "fold_res_test = []\n",
    "\n",
    "index_cols = ['id', 'date', 'time', 'session', 'tsp', 'day_order']\n",
    "for train, test in kf.split(pts):\n",
    "    \n",
    "    train_pt = pts[train]\n",
    "    test_pt = pts[test]\n",
    "    \n",
    "    # set aside training set\n",
    "    dataset_train = dataset_before[dataset_before.id.isin(train_pt)].\\\n",
    "        append(dataset_after[dataset_after.id.isin(train_pt)])\n",
    "    XTrain = dataset_train.drop(index_cols, axis=1)\n",
    "    XTrainTsp = pd.to_datetime(dataset_train.tsp)\n",
    "    XTrainTimeVector = (XTrainTsp - np.datetime64('1970-01-01 00:00:00')) / np.timedelta64(1, 's')\n",
    "    XTrainTimeVector.head()\n",
    "    scaler = RobustScaler()\n",
    "    XTrainScaled = scaler.fit_transform(XTrain)\n",
    "    train_ids = dataset_train[['id','tsp']].sort_values(by=['id', 'tsp']).id.values\n",
    "    train_ids_idx = dataset_train[['id','tsp']].sort_values(by=['id', 'tsp']).index.values\n",
    "    sequtial_idx_1 = train_ids[:-1] == train_ids[1:]\n",
    "    sequtial_idx_2 = np.insert(sequtial_idx_1, 0, False)\n",
    "    sequtial_idx_1 = np.append(sequtial_idx_1, False)\n",
    "    sm_on_idx = []\n",
    "    sm_off_idx = []\n",
    "\n",
    "    for i, idx_1 in enumerate(train_ids_idx[sequtial_idx_1]):\n",
    "        idx_2 = train_ids_idx[sequtial_idx_2][i]\n",
    "        row_i_1 = dataset_train.index.get_loc(idx_1)\n",
    "        row_i_2 = dataset_train.index.get_loc(idx_2)\n",
    "        sm_on_idx.append(row_i_2)\n",
    "        sm_off_idx.append(row_i_1)\n",
    "\n",
    "    sm_on_idx = np.add(sm_on_idx,1)\n",
    "    sm_off_idx = np.add(sm_off_idx,1)\n",
    "    \n",
    "    ### Call Learning Procedure ###\n",
    "    res = train_model_in_R()\n",
    "    print \"split:\", train_pt, test_pt\n",
    "    \n",
    "    # test dataset\n",
    "    dataset_test = dataset_before[dataset_before.id.isin(test_pt)]\\\n",
    "        .append(dataset_after[dataset_after.id.isin(test_pt)])\n",
    "    XTest = dataset_test.drop(index_cols, axis=1)\n",
    "    XTestScaled = scaler.transform(XTest)        \n",
    "\n",
    "    acc = []\n",
    "    weights = []\n",
    "    res_train_list = []\n",
    "    res_test_list = []\n",
    "    for i,la in enumerate(lo):\n",
    "        %R -i i -o w w = res[[i+1]]$estimate\n",
    "        res_train = evaluate(XTrainScaled, w)\n",
    "        res_test = evaluate(XTestScaled, w)\n",
    "        acc.append([(i+1), lo[i], ls[i], res_train['accuracy'], res_test['accuracy']])\n",
    "        weights.append(w)\n",
    "        res_train_list.append(res_train)\n",
    "        res_test_list.append(res_test)\n",
    "    fold_accuracy.append(acc)\n",
    "    fold_weights.append(weights)\n",
    "    fold_train_pt.append(train_pt)\n",
    "    fold_test_pt.append(test_pt)\n",
    "    fold_scaler.append(scaler)\n",
    "    fold_res_train.append(res_train_list)\n",
    "    fold_res_test.append(res_test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carry Out Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# select best hyper parameters from validation set and apply to test set\n",
    "fold_models = []\n",
    "best_acc = []\n",
    "for i, acc in enumerate(fold_accuracy):\n",
    "    model = {}\n",
    "    train_acc = [val[3] for val in acc]\n",
    "    test_acc = [val[4] for val in acc]\n",
    "    best_wi = train_acc.index(max(train_acc))\n",
    "    model['weights'] = fold_weights[i][best_wi]\n",
    "    model['scaler'] = fold_scaler[i]\n",
    "    model['wi'] = best_wi\n",
    "    fold_models.append(model)\n",
    "    print best_wi, train_acc[best_wi], test_acc[best_wi], max(test_acc)\n",
    "    best_acc.append(test_acc[best_wi])\n",
    "np.mean(best_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Feature Importance in Learned Model (Weight Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def weight_analysis(models, names):\n",
    "    for i, m in enumerate(models):\n",
    "        if i == 0:\n",
    "            weights = m['weights']\n",
    "        else:\n",
    "            weights += m['weights']\n",
    "    weights /= len(models)\n",
    "    df = pd.DataFrame(weights, index=names, columns=['weight'])\n",
    "    ii = df.weight.abs().sort_values(ascending=False)\n",
    "    df[\"scaled\"] = df.weight / max(df.weight.abs())\n",
    "    print df.scaled[ii.index].head(30)\n",
    "    return df\n",
    "\n",
    "def get_fold_test_scores(test_pt, test_scores):\n",
    "    # get idx: id and tsp\n",
    "    df = dataset_before[dataset_before.id.isin(test_pt)][['id','tsp']]\\\n",
    "        .append(dataset_after[dataset_after.id.isin(test_pt)][['id','tsp']])\n",
    "    # get score columns\n",
    "    for item in test_scores:\n",
    "        if item.startswith('scores'):\n",
    "            df[item] = test_scores[item]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, model in enumerate(fold_models):\n",
    "    wi = model['wi']\n",
    "    print i, wi\n",
    "    if i == 0:\n",
    "        scores = get_fold_test_scores(fold_test_pt[i], fold_res_test[i][wi])\n",
    "    else:\n",
    "        scores = scores.append(get_fold_test_scores(fold_test_pt[i], fold_res_test[i][wi]))\n",
    "\n",
    "scores.tsp = pd.to_datetime(scores.tsp)\n",
    "\n",
    "df = weight_analysis(fold_models, XTrain.columns.values)\n",
    "print len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"abs_w\"] = df.weight.abs()\n",
    "df[\"abs_w_scale\"] = 100* (df.abs_w - df.abs_w.min()) / df.abs_w.max() - df.abs_w.min()\n",
    "df.abs_w_scale.sort_values(ascending=False).to_csv('sorted_weight.1231.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.abs_w_scale[df.abs_w_scale > 30].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.abs_w_scale[df.abs_w_scale < 1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.abs_w_scale[df.abs_w_scale < 1].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores_before = pd.DataFrame()\n",
    "for id in scores.id.unique():\n",
    "    pt_scores = scores[scores.id == id]\n",
    "    l = len(pt_scores)/2\n",
    "    scores_before = scores_before.append(pt_scores[:l])\n",
    "    \n",
    "scores.to_csv('pt_scores_v2.1231.csv', index=False)\n",
    "scores_before.to_csv('pt_scores_v2_before.1231.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale Learned Scores Between 0-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaled_scores = scores.copy()\n",
    "scaler100 = RobustScaler(quantile_range=(15.0, 85.0))\n",
    "scaler100.fit(scaled_scores.scores)\n",
    "scaled_scores['scores_scaled'] = 50*scaler100.transform(scaled_scores.scores) + 50\n",
    "scaled_scores.scores_scaled[(scaled_scores.scores_scaled > 100)] = 100\n",
    "scaled_scores.scores_scaled[(scaled_scores.scores_scaled < 0)] = 0\n",
    "\n",
    "print scaled_scores.scores_scaled.mean(), scaled_scores.scores_scaled.std() \\\n",
    "    , scaled_scores.scores_scaled.quantile(.25), scaled_scores.scores_scaled.quantile(.75)\n",
    "scaled_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaled_stats = scaled_scores.copy()\n",
    "\n",
    "scaler100.scale_, scaler100.center_\n",
    "\n",
    "c = 50*(-scaler100.center_/scaler100.scale_)/5\n",
    "print(c)\n",
    "scaled_stats['scores_voice'] = c + scaled_stats.scores_voice/scaler100.scale_*50\n",
    "scaled_stats['scores_balance'] = c + scaled_stats.scores_balance/scaler100.scale_*50\n",
    "scaled_stats['scores_tap'] = c + scaled_stats.scores_tap/scaler100.scale_*50\n",
    "scaled_stats['scores_react'] = c + scaled_stats.scores_react/scaler100.scale_*50\n",
    "scaled_stats['scores_gait'] = c + scaled_stats.scores_gait/scaler100.scale_*50\n",
    "scaled_stats[['scores_voice', 'scores_balance', 'scores_gait', 'scores_tap', 'scores_react', 'scores_scaled']].abs().sum()/305694.031681"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
